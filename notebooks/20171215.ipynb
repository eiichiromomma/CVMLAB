{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pythonを使って顔ランドマークで遊んでみよう\n",
    "\n",
    "今回はPythonを使ったプログラミングをやってみます。ただの数値計算では面白くないので\n",
    "\n",
    "1. WebCAMを使って自分の顔をキャプチャ\n",
    "2. 顔検出\n",
    "3. 顔ランドマーク検出\n",
    "4. ランドマークを使って何かやる\n",
    "\n",
    "という流れです。\n",
    "\n",
    "## 使うパッケージ\n",
    "\n",
    "この例では\n",
    "\n",
    "* OpenCV: 画像処理ライブラリ(cv2)\n",
    "* dlib: 機械学習ライブラリ\n",
    "\n",
    "を使います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. WebCAMを使って自分の顔をキャプチャ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "まず，OpenCV(cv2)とdlibを使う宣言をします。C言語の#includeみたいなもんです。\n",
    "セルが緑色の状態(青だったらEnterを押す)でSHIFT+Enterを押して下さい。そうするとIn[?]となっているセル内のPython文が実行されます。\n",
    "その際， Errorのようなメッセージが出なければ成功です。メッセージは英語ですが少し気合を入れれば読めます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これでdlibとcv2が使えるようになりました。dlib.あるいはcv2.の後に関数名を付けることでそれぞれの機能を呼び出せます。早速WebCAMを使えるようにしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "カメラのタリーが光りましたか? 光らない場合は括弧の中の数字を1や2に変えてみて下さい。\n",
    "\n",
    "次に画像をキャプチャします。カメラに目線を送りながら次のセルを実行しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ret, img = cap.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "capはWebCAMを使うための操縦桿(ハンドル)と思って下さい。それにread(読め)と命令した訳です。では，成功したか確認しましょう。readという関数(機能)は成功したか否かの結果と，画像を返してくれます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trueと出ましたか? 出ていれば成功です。画像を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自分の顔が出てきましたか? waitKey(2000)は2000ms待って終了する意味です。この2000を0にすると特別な意味になり，入力待ちになります。(ウィンドウを選択してアクティブな状態にしてから何かキーを押して下さい。Outに何か数字が出るでしょう。この数字はキーの認識番号とでも思って下さい。)\n",
    "\n",
    "カメラが暗い場合はもう一度cap.read()のところを実行してみてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 顔検出\n",
    "\n",
    "さて，顔検出をやってみます。OpenCVにも機能がありますがdlibの機能を使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detectorはdlibのget(よこせ) frontal(正面の) face(顔) detector(検出器)の結果。という意味です。要するに今度は顔検出の操縦桿がdetectorということです。では早速使ってみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dets = detector(img, 1)\n",
    "len(dets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"1\"以上の数字が出てきたら成功です。これは検出した顔の数です。1行目で画像imgから， upsamplingを1回だけして(色々な大きさの顔に対応する処理)，その結果をdetsに入れてます。\n",
    "\n",
    "ではdetsの中身を見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rectangle(262,139,485,361)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rectangle(xxx, xxx, xxx, xxx)と出てきましたね。これはdlibのrectangleというモノです。訳がわからないのでdlib.rectangle?と実行してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dlib.rectangle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "恐らく\n",
    "```Python\n",
    "Docstring:      This object represents a rectangular area of an image.\n",
    "Init docstring:\n",
    "__init__( (object)arg1) -> None\n",
    "\n",
    "__init__( (object)arg1, (int)left, (int)top, (int)right, (int)bottom) -> None\n",
    "File:           \n",
    "Type:           class\n",
    "```\n",
    "のような表示が出てきたと思います。詳しく説明しませんが，rectangle(四角形)にleft, top, right, bottomとくれば何となく想像できるでしょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262\n",
      "139\n",
      "485\n",
      "361\n"
     ]
    }
   ],
   "source": [
    "print(dets[0].left())\n",
    "print(dets[0].top())\n",
    "print(dets[0].right())\n",
    "print(dets[0].bottom())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答えは四角形の左上，右下の座標です。では画像に四角形を重ねてみましょう。ここではcv2の機能を使います。使い方を見て実行してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2.rectangle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.rectangle(img, (dets[0].left(), dets[0].top()), (dets[0].right(), dets[0].bottom()), (255, 0, 0))\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "顔に四角形が重なりましたか?失敗した場合には顔が正面を向いていないか，rectangleに渡す座標が間違えています。ちなみにこれを連続的に実行すると以下のようになります。(ウィンドウをアクティブにしてESCキーを押すと止まります)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "cap = cv2.VideoCapture(0)\n",
    "while not cap.isOpened():\n",
    "    pass\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "key = 0\n",
    "while key != 27:\n",
    "    ret, img = cap.read()\n",
    "    dets = detector(img, 1)\n",
    "    if len(dets) > 0:\n",
    "        img = cv2.rectangle(img, (dets[0].left(), dets[0].top()), (dets[0].right(), dets[0].bottom()), (255, 0, 0))\n",
    "        cv2.imshow('image', img)\n",
    "    else:\n",
    "        cv2.imshow('image', img)\n",
    "    key = cv2.waitKey(10)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 顔ランドマーク検出\n",
    "\n",
    "いよいよ顔ランドマークです。顔ランドマークは学習済みのデータ，shape_predictor_68_face_landmarks.datを使います。これは顔ランドマーク68点を検出できます。その前に仕切り直しです。また顔をカメラに向けて以下を実行して下さい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while not cap.isOpened():\n",
    "    pass\n",
    "ret, img = cap.read()\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "イマイチな場合はもう一度下のセルを実行しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret, img = cap.read()\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では顔ランドマークの検出器の操縦桿を作りましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もし，エラーが出てしまったらshape_predictor_68_face_landmarks.datファイルがこのノートブックファイルと同じ場所にないせいです。ネットからダウンロードするなり先生に聞くなりして解決しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手順としてはdetectorで顔検出し，predictorで検出した顔領域内の顔ランドマークを検出，という流れです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dets = detector(img, 1)\n",
    "shape = predictor(img, dets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dlib.full_object_detection at 0x2aa200b29d0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "結果を入れたshapeを見てみようと思ったらdlib.full_object_detection at ....と出てきました。?を使って調べてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dlib.full_object_detection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "Docstring:      This object represents the location of an object in an image along with the     positions of each of its constituent parts.\n",
    "Init docstring:\n",
    "__init__( (object)arg1) -> None\n",
    "\n",
    "__init__( (object)arg1, (object)arg2, (object)arg3) -> object :\n",
    "    requires \n",
    "        - rect: dlib rectangle \n",
    "        - parts: list of dlib points\n",
    "File:          \n",
    "Type:           class\n",
    "```\n",
    "どうもrectとpartsがあるようです。rectは恐らくdetsと同じものでしょう。ではpartsはどうでしょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape.parts?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "Docstring:\n",
    "parts( (full_object_detection)arg1) -> points :\n",
    "    A vector of dlib points representing all of the parts.\n",
    "Type:      method\n",
    "```\n",
    "と出てきました。実行すると場所が詰まったベクトルが出てくると言っています。ベクトルの何番目は[]で指定できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "point(236, 147)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape.parts()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出ました。0番です。さて，どこでしょう。これは[ググ](https://www.google.co.jp/search?q=shape_predictor_68_face_landmarks&tbm=isch&tbo=u&source=univ&sa=X&ved=0ahUKEwi8y7GJk4nYAhWHJ5QKHeDmD9QQsAQIZA&biw=1297&bih=1274)ってみましょう。ついでにdlib.pointも調べてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dlib.point?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "Docstring:      This object represents a single point of integer coordinates that maps directly to a dlib::point.\n",
    "Init docstring:\n",
    "__init__( (object)arg1) -> None\n",
    "\n",
    "__init__( (object)arg1, (int)x, (int)y) -> None\n",
    "File:           \n",
    "Type:           class\n",
    "```\n",
    "とあるので，x, yで座標を指定できそうです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n",
      "147\n"
     ]
    }
   ],
   "source": [
    "print(shape.parts()[0].x)\n",
    "print(shape.parts()[0].y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では取り敢えず右目を囲ってみましょう。左端は36番のx，上端は38番のy，右端は39番のx，下端は41番のyを使ってみます。長くなるのでそれぞれx1, y1, x2, y2に代入してしまいましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = shape.parts()[36].x\n",
    "y1 = shape.parts()[38].y\n",
    "x2 = shape.parts()[39].x\n",
    "y2 = shape.parts()[41].y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そしてimgに四角形を書き込んでみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255))\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(2000)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先程の連続処理に手を加えてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "cap = cv2.VideoCapture(0)\n",
    "while not cap.isOpened():\n",
    "    pass\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "key = 0\n",
    "while key != 27:\n",
    "    ret, img = cap.read()\n",
    "    dets = detector(img, 1)\n",
    "    if len(dets) > 0:\n",
    "        shape = predictor(img, dets[0])\n",
    "        x1 = shape.parts()[36].x\n",
    "        y1 = shape.parts()[38].y\n",
    "        x2 = shape.parts()[39].x\n",
    "        y2 = shape.parts()[41].y\n",
    "        img = cv2.rectangle(img, (dets[0].left(), dets[0].top()), (dets[0].right(), dets[0].bottom()), (255, 0, 0))\n",
    "        img = cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255))\n",
    "    cv2.imshow('image', img)\n",
    "    key = cv2.waitKey(10)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 顔ランドマークを使って何かやる\n",
    "\n",
    "さて，最後です。ランドマークを使って雑コラをしてみます。とりあえず改変OKなものを探して[ここ](https://pixabay.com/ja/%E6%BC%AB%E7%94%BB-%E6%B7%B7%E4%B9%B1%E3%81%95%E3%81%9B%E3%82%8B-%E7%9B%AE-%E7%8B%82%E7%89%9B%E7%97%85-%E3%81%8A%E3%81%8B%E3%81%97%E3%81%84-%E6%B7%B7%E4%B9%B1-%E5%95%8F%E9%A1%8C-%E3%83%9E%E3%83%BC%E3%82%AF-718659/)から拾ってきました。\n",
    "\n",
    "また仕切り直しですのでカメラを見て下のセルを実行しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while not cap.isOpened():\n",
    "    pass\n",
    "ret, img = cap.read()\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "イマイチな場合はもう一度下のセルを実行しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret, img = cap.read()\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ではdetectorとpredictorの出番です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dets = detector(img, 1)\n",
    "shape = predictor(img, dets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今度は両目を覆いたいので(x1, y1) = (17のx, 19のy), (x2, y2) = (26のx, 29のy)としました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = shape.parts()[17].x\n",
    "y1 = shape.parts()[19].y\n",
    "x2 = shape.parts()[26].x\n",
    "y2 = shape.parts()[29].y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では囲えてるか確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255))\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では画像の一部置き換えです。Pythonを使うと簡単ですが注意が必要です。\n",
    "\n",
    "```Python\n",
    "置き換える画像の読み込み(cv2.imread)\n",
    "置き換える画像をリサイズ(cv2.resize)，サイズは(x2 - x1, y2 - y1)\n",
    "元画像[yの範囲, xの範囲] = リサイズした置き換える画像\n",
    "```\n",
    "となります。Pythonは通常「行，列」で扱っているので3行目はxとyが逆になっています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img2 = cv2.imread('cartoon-718659_640.png', cv2.IMREAD_ANYCOLOR)\n",
    "newSize = (x2 - x1, y2 - y1)\n",
    "img3 = cv2.resize(img2, newSize)\n",
    "img[y1:y2, x1:x2] = img3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さて，確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', img)\n",
    "cv2.waitKey(2000)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では連続処理にしてみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "cap = cv2.VideoCapture(0)\n",
    "while not cap.isOpened():\n",
    "    pass\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "img2 = cv2.imread('cartoon-718659_640.png', cv2.IMREAD_ANYCOLOR)\n",
    "key = 0\n",
    "while key != 27:\n",
    "    ret, img = cap.read()\n",
    "    dets = detector(img, 1)\n",
    "    if len(dets) > 0:\n",
    "        shape = predictor(img, dets[0])\n",
    "        x1 = shape.parts()[17].x\n",
    "        y1 = shape.parts()[19].y\n",
    "        x2 = shape.parts()[26].x\n",
    "        y2 = shape.parts()[29].y\n",
    "        newSize = (x2 - x1, y2 - y1)\n",
    "        img3 = cv2.resize(img2, newSize)\n",
    "        img[y1:y2, x1:x2] = img3\n",
    "    cv2.imshow('image', img)\n",
    "    key = cv2.waitKey(10)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで今日のゼミは終了です。この顔ランドマークの情報があれば目を大きくしたり，顔だけ美白にしたり，目を少女漫画みたいに置き換えたりもできますね。世に出回っているカメラアプリはこのようにして加工をしています。違和感なく滑らかにする技術がアプリの差とも言えますね。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
